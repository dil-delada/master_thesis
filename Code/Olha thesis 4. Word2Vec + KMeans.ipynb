{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "import numpy as np\n",
    "import io\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text preparation functions\n",
    "\n",
    "def delete_numbers(text):\n",
    "    #input: text as string\n",
    "    #output: string as original text without numbers\n",
    "    new_text = ''.join([i for i in text if not i.isdigit()])\n",
    "    return new_text\n",
    "\n",
    "def tokenization_sent(text):\n",
    "    #input: text as string\n",
    "    #output: list of sentences\n",
    "    return nltk.sent_tokenize(text)\n",
    "\n",
    "def tokenization_words(sentence):\n",
    "    #input: sentence as string\n",
    "    #output: list of words\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "def delete_punct(text):\n",
    "    #input: text as string\n",
    "    #output: string as original text without punctuation\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def delete_stopwords(text, stopwords):\n",
    "    #input: text as string, stopwords as list of stopwords\n",
    "    #output: string as original text without stopwords\n",
    "    new_text = [word for word in tokenization_words(text) if word not in stopwords]\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "en_data = pd.read_csv('en_data.csv')\n",
    "et_data = pd.read_csv('et_data.csv')\n",
    "for i in en_data.columns:\n",
    "    if 'Unnamed' in i:\n",
    "        del en_data[i]\n",
    "for i in et_data.columns:\n",
    "    if 'Unnamed' in i:\n",
    "        del et_data[i]\n",
    "en_data = en_data[~pd.isnull(en_data['Nouns'])]\n",
    "et_data = et_data[~pd.isnull(et_data['Nouns'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Word2Vec model from FastText and use it on Nouns\n",
    "\n",
    "#Detect tokens to import further in Word2Vec\n",
    "def get_tokens(data_original):\n",
    "    #input: data_original as dataframe \n",
    "    #output: list of unique words from 'Nouns' column\n",
    "    #delete nans\n",
    "    data_original = data_original[~pd.isnull(data_original['Nouns'])]\n",
    "    #make copy\n",
    "    data = data_original\n",
    "    #get tokens as list of unique words\n",
    "    data['tokens'] = data['Nouns'].apply(lambda x: [i for i in x.split(' ')])\n",
    "    corpora = data['tokens'].tolist()\n",
    "    tokens = set([item for sublist in corpora for item in sublist])\n",
    "    return tokens\n",
    "\n",
    "#read .vec file as Word2Vec model\n",
    "def load_vectors(fname, corpora_tokens):\n",
    "    #input: fmane as path to mpdel in vec format, corpora_tokens aslist of words in corpora\n",
    "    #output: data as model with all nessasary words\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        if tokens[0] in corpora_tokens:\n",
    "            data[tokens[0]] = list(map(float, tokens[1:]))\n",
    "    return data\n",
    "\n",
    "#transform sentence to vector\n",
    "def sentence_vectorization(sentence, model):\n",
    "    #input: sentence as string, model as pretrained Word2Vec model\n",
    "    #output: vector of input sentence\n",
    "    words = tokenization_words(sentence)\n",
    "    vectors_list = []\n",
    "    for word in words:\n",
    "        v = word_vectorization(word, model)\n",
    "        vectors_list.append(v)\n",
    "    mean_v = np.mean(vectors_list, axis=0)\n",
    "    return mean_v\n",
    "\n",
    "#transform word to vector\n",
    "def word_vectorization(word, model):\n",
    "    #input: word as string, model as pretrained Word2Vec model\n",
    "    #output: vector of input word\n",
    "    try:\n",
    "        v = model[word]\n",
    "    except:\n",
    "        v = np.zeros(300)\n",
    "    return v\n",
    "\n",
    "tokens_en = get_tokens(en_data)\n",
    "model_en = load_vectors('C:/Users/Olha/Documents/cc.en.300.vec', tokens_en)\n",
    "en_data['Description_vector'] = en_data['Nouns'].apply(lambda x: sentence_vectorization(x, model_en))\n",
    "en_data['Tokens_vectors'] = en_data['Nouns'].apply(lambda x: [word_vectorization(i, model_en) for i in tokenization_words(x)])\n",
    "tokens_et = get_tokens(et_data)\n",
    "model_et = load_vectors('C:/Users/Olha/Documents/cc.et.300.vec', tokens_et)\n",
    "et_data['Description_vector'] = et_data['Nouns'].apply(lambda x: sentence_vectorization(x, model_et))\n",
    "et_data['Tokens_vectors'] = et_data['Nouns'].apply(lambda x: [word_vectorization(i, model_et) for i in tokenization_words(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olha\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\Olha\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#use vectors and tokens to make a summary\n",
    "def clustering_summarization(vectors, sentence, number_of_sentences_summary):\n",
    "    #input: vectors as list of vectors for input words, sentence as string, number_of_sentences_summary a number of sentences expected to obtain in summary\n",
    "    #output: summary as string \n",
    "    tokens = tokenization_words(sentence)\n",
    "    kmeans = KMeans(n_clusters = number_of_sentences_summary)\n",
    "    vectors_to_ndarray = np.array([np.array(x) for x in vectors])\n",
    "    kmeans = kmeans.fit(vectors_to_ndarray)\n",
    "    avg = []\n",
    "    for j in range(number_of_sentences_summary):\n",
    "        idx = np.where(kmeans.labels_ == j)[0]\n",
    "        avg.append(np.mean(idx))\n",
    "    closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, vectors_to_ndarray)\n",
    "    ordering = sorted(range(number_of_sentences_summary), key=lambda k: avg[k])\n",
    "    summary = [tokens[closest[idx]] for idx in ordering]\n",
    "    return summary\n",
    "\n",
    "#make summary for each product (to define max 4-5 keywords)\n",
    "en_data['Summary'] = en_data.apply(lambda x: clustering_summarization(x.Tokens_vectors, x.Nouns, min(4, len(tokenization_words(x.Nouns)))), axis = 1)\n",
    "et_data['Summary'] = et_data.apply(lambda x: clustering_summarization(x.Tokens_vectors, x.Nouns, min(5, len(tokenization_words(x.Nouns)))), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>node</th>\n",
       "      <th>text_join</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Description_vector</th>\n",
       "      <th>Tokens_vectors</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;https::nailin.ee::/et/27-akruulvarvid::null::...</td>\n",
       "      <td>node517e8478b3641044f1e2e2bbc31afa</td>\n",
       "      <td>AkruFCuFClvuErv One Stroke Phthalo Green ml</td>\n",
       "      <td>AkruFCuFClvuErv Stroke Phthalo Green ml</td>\n",
       "      <td>[0.0528, -0.02636, -0.03886, -0.05032, -0.0188...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[Stroke, AkruFCuFClvuErv, Phthalo, ml]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http::www.kalastussport.ee::/136-taliridvad::...</td>\n",
       "      <td>nodef5d0383018d768c2279c3541adc8f1a</td>\n",
       "      <td>Winter rod AKARA Legend</td>\n",
       "      <td>Winter rod AKARA Legend</td>\n",
       "      <td>[-0.037375, -0.014125000000000002, 0.0134, 0.0...</td>\n",
       "      <td>[[0.0187, 0.0226, -0.0533, 0.0044, 0.0299, -0....</td>\n",
       "      <td>[Winter, rod, AKARA, Legend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;http::www.ittgroup.ee::/en/new-products::null...</td>\n",
       "      <td>nodefeb891dd8590e0d85f9c685e4642449</td>\n",
       "      <td>Digital pressure sensor BMP</td>\n",
       "      <td>Digital pressure sensor BMP</td>\n",
       "      <td>[0.013125000000000005, 0.0393, 0.06575, -0.000...</td>\n",
       "      <td>[[-0.0496, 0.0661, 0.0464, -0.0271, -0.0263, 0...</td>\n",
       "      <td>[Digital, pressure, sensor, BMP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;http::www.ittgroup.ee::/en/31-converters::nul...</td>\n",
       "      <td>node67109f1f1de73f41d2979d4561221</td>\n",
       "      <td>Analogdigital converter bit ADS</td>\n",
       "      <td>converter bit ADS</td>\n",
       "      <td>[-0.0014333333333333327, -0.026866666666666667...</td>\n",
       "      <td>[[-0.0345, -0.0349, 0.0286, 0.0241, 0.0228, 0....</td>\n",
       "      <td>[converter, bit, ADS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;http::www.ittgroup.ee::/en/38-prototyping-and...</td>\n",
       "      <td>node3f349ca61d31b5f8c6bfe56bdb8081</td>\n",
       "      <td>Power Charger VA</td>\n",
       "      <td>Power Charger VA</td>\n",
       "      <td>[-0.060733333333333334, 0.0726, 0.207433333333...</td>\n",
       "      <td>[[-0.0726, 0.062, 0.1646, -0.0548, -0.0151, 0....</td>\n",
       "      <td>[Power, Charger, VA]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  <https::nailin.ee::/et/27-akruulvarvid::null::...   \n",
       "1  <http::www.kalastussport.ee::/136-taliridvad::...   \n",
       "2  <http::www.ittgroup.ee::/en/new-products::null...   \n",
       "3  <http::www.ittgroup.ee::/en/31-converters::nul...   \n",
       "4  <http::www.ittgroup.ee::/en/38-prototyping-and...   \n",
       "\n",
       "                                  node  \\\n",
       "0   node517e8478b3641044f1e2e2bbc31afa   \n",
       "1  nodef5d0383018d768c2279c3541adc8f1a   \n",
       "2  nodefeb891dd8590e0d85f9c685e4642449   \n",
       "3    node67109f1f1de73f41d2979d4561221   \n",
       "4   node3f349ca61d31b5f8c6bfe56bdb8081   \n",
       "\n",
       "                                     text_join  \\\n",
       "0  AkruFCuFClvuErv One Stroke Phthalo Green ml   \n",
       "1                      Winter rod AKARA Legend   \n",
       "2                  Digital pressure sensor BMP   \n",
       "3              Analogdigital converter bit ADS   \n",
       "4                             Power Charger VA   \n",
       "\n",
       "                                     Nouns  \\\n",
       "0  AkruFCuFClvuErv Stroke Phthalo Green ml   \n",
       "1                  Winter rod AKARA Legend   \n",
       "2              Digital pressure sensor BMP   \n",
       "3                        converter bit ADS   \n",
       "4                         Power Charger VA   \n",
       "\n",
       "                                  Description_vector  \\\n",
       "0  [0.0528, -0.02636, -0.03886, -0.05032, -0.0188...   \n",
       "1  [-0.037375, -0.014125000000000002, 0.0134, 0.0...   \n",
       "2  [0.013125000000000005, 0.0393, 0.06575, -0.000...   \n",
       "3  [-0.0014333333333333327, -0.026866666666666667...   \n",
       "4  [-0.060733333333333334, 0.0726, 0.207433333333...   \n",
       "\n",
       "                                      Tokens_vectors  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1  [[0.0187, 0.0226, -0.0533, 0.0044, 0.0299, -0....   \n",
       "2  [[-0.0496, 0.0661, 0.0464, -0.0271, -0.0263, 0...   \n",
       "3  [[-0.0345, -0.0349, 0.0286, 0.0241, 0.0228, 0....   \n",
       "4  [[-0.0726, 0.062, 0.1646, -0.0548, -0.0151, 0....   \n",
       "\n",
       "                                  Summary  \n",
       "0  [Stroke, AkruFCuFClvuErv, Phthalo, ml]  \n",
       "1            [Winter, rod, AKARA, Legend]  \n",
       "2        [Digital, pressure, sensor, BMP]  \n",
       "3                   [converter, bit, ADS]  \n",
       "4                    [Power, Charger, VA]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have keywords, need clusters\n",
    "# Link words with at least one common keywords\n",
    "\n",
    "def get_unique_keywords(data):\n",
    "    keywords_series = data.Summary\n",
    "    all_keywords = []\n",
    "    for keywords_list in keywords_series:\n",
    "        for keyword in keywords_list:\n",
    "            all_keywords.append(keyword)\n",
    "    unique_keywords = list(set(all_keywords))\n",
    "    Data = {'Keyword_unique':  unique_keywords, 'Keyword_number': list(range(0, len(unique_keywords)))}\n",
    "    df = DataFrame (Data, columns = ['Keyword_unique', 'Keyword_number'])\n",
    "    return df\n",
    "\n",
    "keywords_en = get_unique_keywords(en_data)\n",
    "keywords_et = get_unique_keywords(et_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_keywords_connection(summary, keywords):\n",
    "    numbers = []\n",
    "    for key in summary:\n",
    "        numbers.append(keywords.Keyword_number[keywords['Keyword_unique'] == key])\n",
    "    return numbers\n",
    "\n",
    "en_data['Keywords_numbers'] = en_data.Summary.apply(lambda x: detect_keywords_connection(x, keywords_en))\n",
    "et_data['Keywords_numbers'] = et_data.Summary.apply(lambda x: detect_keywords_connection(x, keywords_et))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>node</th>\n",
       "      <th>text_join</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Description_vector</th>\n",
       "      <th>Tokens_vectors</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Keywords_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;https::nailin.ee::/et/27-akruulvarvid::null::...</td>\n",
       "      <td>node517e8478b3641044f1e2e2bbc31afa</td>\n",
       "      <td>AkruFCuFClvuErv One Stroke Phthalo Green ml</td>\n",
       "      <td>AkruFCuFClvuErv Stroke Phthalo Green ml</td>\n",
       "      <td>[0.0528, -0.02636, -0.03886, -0.05032, -0.0188...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[Stroke, AkruFCuFClvuErv, Phthalo, ml]</td>\n",
       "      <td>[[2159], [9833], [12269], [14957]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http::www.kalastussport.ee::/136-taliridvad::...</td>\n",
       "      <td>nodef5d0383018d768c2279c3541adc8f1a</td>\n",
       "      <td>Winter rod AKARA Legend</td>\n",
       "      <td>Winter rod AKARA Legend</td>\n",
       "      <td>[-0.037375, -0.014125000000000002, 0.0134, 0.0...</td>\n",
       "      <td>[[0.0187, 0.0226, -0.0533, 0.0044, 0.0299, -0....</td>\n",
       "      <td>[Winter, rod, AKARA, Legend]</td>\n",
       "      <td>[[7892], [9829], [23856], [30916]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;http::www.ittgroup.ee::/en/new-products::null...</td>\n",
       "      <td>nodefeb891dd8590e0d85f9c685e4642449</td>\n",
       "      <td>Digital pressure sensor BMP</td>\n",
       "      <td>Digital pressure sensor BMP</td>\n",
       "      <td>[0.013125000000000005, 0.0393, 0.06575, -0.000...</td>\n",
       "      <td>[[-0.0496, 0.0661, 0.0464, -0.0271, -0.0263, 0...</td>\n",
       "      <td>[Digital, pressure, sensor, BMP]</td>\n",
       "      <td>[[23158], [23248], [21563], [28042]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;http::www.ittgroup.ee::/en/31-converters::nul...</td>\n",
       "      <td>node67109f1f1de73f41d2979d4561221</td>\n",
       "      <td>Analogdigital converter bit ADS</td>\n",
       "      <td>converter bit ADS</td>\n",
       "      <td>[-0.0014333333333333327, -0.026866666666666667...</td>\n",
       "      <td>[[-0.0345, -0.0349, 0.0286, 0.0241, 0.0228, 0....</td>\n",
       "      <td>[converter, bit, ADS]</td>\n",
       "      <td>[[6799], [636], [5169]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;http::www.ittgroup.ee::/en/38-prototyping-and...</td>\n",
       "      <td>node3f349ca61d31b5f8c6bfe56bdb8081</td>\n",
       "      <td>Power Charger VA</td>\n",
       "      <td>Power Charger VA</td>\n",
       "      <td>[-0.060733333333333334, 0.0726, 0.207433333333...</td>\n",
       "      <td>[[-0.0726, 0.062, 0.1646, -0.0548, -0.0151, 0....</td>\n",
       "      <td>[Power, Charger, VA]</td>\n",
       "      <td>[[17862], [22422], [8494]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  <https::nailin.ee::/et/27-akruulvarvid::null::...   \n",
       "1  <http::www.kalastussport.ee::/136-taliridvad::...   \n",
       "2  <http::www.ittgroup.ee::/en/new-products::null...   \n",
       "3  <http::www.ittgroup.ee::/en/31-converters::nul...   \n",
       "4  <http::www.ittgroup.ee::/en/38-prototyping-and...   \n",
       "\n",
       "                                  node  \\\n",
       "0   node517e8478b3641044f1e2e2bbc31afa   \n",
       "1  nodef5d0383018d768c2279c3541adc8f1a   \n",
       "2  nodefeb891dd8590e0d85f9c685e4642449   \n",
       "3    node67109f1f1de73f41d2979d4561221   \n",
       "4   node3f349ca61d31b5f8c6bfe56bdb8081   \n",
       "\n",
       "                                     text_join  \\\n",
       "0  AkruFCuFClvuErv One Stroke Phthalo Green ml   \n",
       "1                      Winter rod AKARA Legend   \n",
       "2                  Digital pressure sensor BMP   \n",
       "3              Analogdigital converter bit ADS   \n",
       "4                             Power Charger VA   \n",
       "\n",
       "                                     Nouns  \\\n",
       "0  AkruFCuFClvuErv Stroke Phthalo Green ml   \n",
       "1                  Winter rod AKARA Legend   \n",
       "2              Digital pressure sensor BMP   \n",
       "3                        converter bit ADS   \n",
       "4                         Power Charger VA   \n",
       "\n",
       "                                  Description_vector  \\\n",
       "0  [0.0528, -0.02636, -0.03886, -0.05032, -0.0188...   \n",
       "1  [-0.037375, -0.014125000000000002, 0.0134, 0.0...   \n",
       "2  [0.013125000000000005, 0.0393, 0.06575, -0.000...   \n",
       "3  [-0.0014333333333333327, -0.026866666666666667...   \n",
       "4  [-0.060733333333333334, 0.0726, 0.207433333333...   \n",
       "\n",
       "                                      Tokens_vectors  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1  [[0.0187, 0.0226, -0.0533, 0.0044, 0.0299, -0....   \n",
       "2  [[-0.0496, 0.0661, 0.0464, -0.0271, -0.0263, 0...   \n",
       "3  [[-0.0345, -0.0349, 0.0286, 0.0241, 0.0228, 0....   \n",
       "4  [[-0.0726, 0.062, 0.1646, -0.0548, -0.0151, 0....   \n",
       "\n",
       "                                  Summary  \\\n",
       "0  [Stroke, AkruFCuFClvuErv, Phthalo, ml]   \n",
       "1            [Winter, rod, AKARA, Legend]   \n",
       "2        [Digital, pressure, sensor, BMP]   \n",
       "3                   [converter, bit, ADS]   \n",
       "4                    [Power, Charger, VA]   \n",
       "\n",
       "                       Keywords_numbers  \n",
       "0    [[2159], [9833], [12269], [14957]]  \n",
       "1    [[7892], [9829], [23856], [30916]]  \n",
       "2  [[23158], [23248], [21563], [28042]]  \n",
       "3               [[6799], [636], [5169]]  \n",
       "4            [[17862], [22422], [8494]]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data_copy = en_data\n",
    "en_data_copy = en_data_copy.drop(columns = ['Description_vector', 'Tokens_vectors'])\n",
    "en_data_copy.to_csv('Results/en_data_wod2vec_kmeans.csv')\n",
    "\n",
    "et_data_copy = et_data\n",
    "et_data_copy = et_data_copy.drop(columns = ['Description_vector', 'Tokens_vectors'])\n",
    "et_data_copy.to_csv('Results/et_data_wod2vec_kmeans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make summary for all products dataset\n",
    "topics_en = clustering_summarization(en_data.Description_vector, en_data.Nouns, 20)\n",
    "topics_et = clustering_summarization(et_data.Description_vector, et_data.Nouns, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vogue VOS N. DS OSRAM XENARC COOL BLUE INTENSE xenon HID pirn. Komplekt KING laud ja tooli. mm Aquamarine F. ASUS VGA PCIE GT GB GDDRGTGD ASUSASUS VGA PCIE GT GB GDDRGTGD ASUS. PRODUCTuABookend homeoffice decorationDETAILS Did tigers patterns meanings sign head symbol foruAa King Chinese Wow tiger Zuny house pieces world name Mateo materials injure animals production mood things lifeuAUSEuAhis books doors decoration table shelf ItuAlooks varietyuAof interiorsuAand WEIGHTuAFEATURESHANDMADEuAand weightLIMITED EDITIONuA pcs family belly name belonginguAto edition AlsouAsome models number auAPASSPORTuAwithuAinformation Zuny FauxuALeatheruAMicro SuedeInside uAuA Iron PelletsuASuperfineuAPolyester FiberCOLOUR uATan Edition pcs MateouAuFuuuBuuuuuuuF uFuuuFuEuu ZunyuCuuuuuuuBuBuuDuuuuu uDuAuEuAuEuu NOTES PLEASE NOTE NOT toy children years SHIPPING INFORMATION costuAuA FREE shipping worldwide Ships touA EU Russia Ukraine Belarus USA PolicyuA EASYuAThis item explanations months accordance Return Policy Packaging Brown bag logo orange paper place parcel withuAcushions BeautifulThinus. KriidivuErv ml antiiklilla. Tommy Denander Signature ModeluASolid Alder Flamed Maple AAA selectionuA mm scale mm widthSet Maple neck Vprofile Ebony fingerboard frets. V W BXd. Ekraan cm ekraan IPS Retina K tehnoloogiaga x pikslitu Protsessor GHz Intel Core iu MuElu GB DDRL MHzu MuElu GB kuFvaketasu Graafika Intel HD Graphics Ekraan cm ekraan IPS Apple iMac Retina K MK i GB ram TB HDD Apple iMac Retina K. Legends Queen hills teeraamat. HTL Opaque Antique Rose. Prisen pakke puE stk Crystal AB. Doublesided linen terry washer means Regularly washer body tone blood circulation Linen fiber microclimate Linen products products EXCLUSIVE. Zalmanovi Vannid TuErpentiini emulsioon ml Farm Effekt Zalmanovi. Hambaharja tops. Size kondoomid mille uFCmbermuFuFt cm laius cm Pakis My Size mm tk. Kaldlaser AS. price peruA pcsuAThe pictures illustrationinformation Crystal Labrador Half. CT Rain Wind Deflectors visors air weather conditions fogging passenger comfort slimline profile CT deflectors model level fit finishCitroen CCrosser'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "149",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-085550966852>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mkey_indexes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mindexes_en\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_indexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0men_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopics_en\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mindexes_et\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_indexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0met_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopics_et\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-085550966852>\u001b[0m in \u001b[0;36mget_indexes\u001b[1;34m(data, topics)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mkey_indexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Nouns'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[0mkey_indexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mkey_indexes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   2558\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2559\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 2560\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   2561\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2562\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 149"
     ]
    }
   ],
   "source": [
    "#get indexes of products that formed summary for whole en/et dataset\n",
    "def get_indexes(data, topics):\n",
    "    key_indexes = []\n",
    "    for i in range(len(data)):\n",
    "        if data['Nouns'][i] in topics:\n",
    "            key_indexes.append(i)\n",
    "    return key_indexes\n",
    "\n",
    "indexes_en = get_indexes(en_data, topics_en)\n",
    "indexes_et = get_indexes(et_data, topics_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "srting = 'CT Rain Wind Deflectors visors air weather conditions fogging passenger comfort slimline profile CT deflectors model level fit finishCitroen CCrosser'\n",
    "if srting in topics_en:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
